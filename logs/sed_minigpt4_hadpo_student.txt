[2024-03-31 20:08:07,200] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading VIT
Loading VIT Done
Loading Q-Former
Loading Q-Former Done
Loading LLAMA
lora parameters:
lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'k_proj', 'v_proj']
trainable params: 50,331,648 || all params: 6,788,755,456 || trainable%: 0.7413972756304863
Loading LLAMA Done
freeze weight for lora only finetuning
freeze bias for lora only finetuning
Load 4 training prompts
Prompt Example 
###Human: <Img><ImageHere></Img>Is the person looking straight at the screen?  ###Assistant: 
Load BLIP2-LLM Checkpoint: /home/tony/HA-DPO/ha_dpo/models/minigpt4/prerained_minigpt4_7b.pth
Loading VIT
Loading VIT Done
Loading Q-Former
Loading Q-Former Done
Loading LLAMA
Loading LLAMA Done
freeze weight for lora only finetuning
freeze bias for lora only finetuning
Load 4 training prompts
Prompt Example 
###Human: <Img><ImageHere></Img>Is the person looking straight at the screen? Is the person looking down at the paper? Is the person looking away? ###Assistant: 
Load BLIP2-LLM Checkpoint: /home/tony/HA-DPO/ha_dpo/models/minigpt4/prerained_minigpt4_7b.pth
Load CCSBUAlign Data...
Loaded 1575 CCSBUAlign data
Data Example:
Person is looking down at the paper
Load Augmented Caption Data...
sampleing strategy: offline
Loaded 1733 description data
Data example:
Chosen: A group of people can be seen in the image, skiing down a snowy slope. Every individual is appropriately dressed in ski gear, which includes helmets, goggles, and skis. Among them, a woman in ski gear stands out as she smiles directly at the camera while firmly holding onto her ski poles. The snowy hill accommodates four skiers, all of whom have equipped themselves with helmets, goggles, and ski poles. The image skillfully captures a winter sport scenario, showcasing the skiers' preparedness for an exciting adventure.
Rejected: In the image, a snowy slope is filled with skiers wearing helmets, goggles, and skis. One person stands at the top, holding a ski pole, as the others ski down. Snow covers the slope and trees can be seen in the background. The sky is blue with distant clouds, creating a mood of excitement and adventure.
Load POPE Data...
Loaded 7111 pope data
Data Example:
No, the words "Bury Street Station" are not written on the building.
Yes, the words "Bury Street Station" are written on the building.
[2024-03-31 20:09:25,940] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-31 20:09:25,940] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-31 20:09:26,269] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-31 20:09:26,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-31 20:09:26,817] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-31 20:09:26,969] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-31 20:09:26,969] [INFO] [utils.py:801:see_memory_usage] MA 10.63 GB         Max_MA 10.63 GB         CA 10.97 GB         Max_CA 11 GB 
[2024-03-31 20:09:26,969] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.26 GB, percent = 8.5%
[2024-03-31 20:09:27,099] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-31 20:09:27,099] [INFO] [utils.py:801:see_memory_usage] MA 10.63 GB         Max_MA 10.63 GB         CA 10.97 GB         Max_CA 11 GB 
[2024-03-31 20:09:27,099] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.26 GB, percent = 8.5%
[2024-03-31 20:09:27,101] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-31 20:09:27,101] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7d5519ce5b20>
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-31 20:09:27,102] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   train_batch_size ............. 1
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-31 20:09:27,103] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-31 20:09:27,103] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 2.5836, 'grad_norm': 0.5514082620032191, 'learning_rate': 4.000000000000001e-06, 'rewards/chosen': -0.0018889904022216797, 'rewards/rejected': -0.000828695367090404, 'rewards/accuracies': 0.25, 'rewards/margins': -0.0010602951515465975, 'policy_logps/rejected': -7.9725022315979, 'policy_logps/chosen': -13.107110023498535, 'referece_logps/rejected': -7.9642157554626465, 'referece_logps/chosen': -13.08821964263916, 'logits/rejected': -1.9665393829345703, 'logits/chosen': -2.0001790523529053, 'epoch': 0.0}
{'loss': 2.3657, 'grad_norm': 0.7548776406805573, 'learning_rate': 8.000000000000001e-06, 'rewards/chosen': -0.003045898862183094, 'rewards/rejected': 0.005647755227982998, 'rewards/accuracies': 0.25, 'rewards/margins': -0.008693653158843517, 'policy_logps/rejected': -22.027557373046875, 'policy_logps/chosen': -6.1263298988342285, 'referece_logps/rejected': -22.08403778076172, 'referece_logps/chosen': -6.0958709716796875, 'logits/rejected': -1.9891719818115234, 'logits/chosen': -1.8413128852844238, 'epoch': 0.0}
{'loss': 2.0862, 'grad_norm': 1.0853306014388222, 'learning_rate': 1.2e-05, 'rewards/chosen': -0.023257959634065628, 'rewards/rejected': 0.02159332111477852, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04485128074884415, 'policy_logps/rejected': -99.29657745361328, 'policy_logps/chosen': -67.85498809814453, 'referece_logps/rejected': -99.51251220703125, 'referece_logps/chosen': -67.6224136352539, 'logits/rejected': -1.6928812265396118, 'logits/chosen': -1.7425298690795898, 'epoch': 0.0}
{'loss': 1.9791, 'grad_norm': 0.507573144696583, 'learning_rate': 1.6000000000000003e-05, 'rewards/chosen': 0.0058792829513549805, 'rewards/rejected': -0.00556151894852519, 'rewards/accuracies': 0.75, 'rewards/margins': 0.011440801434218884, 'policy_logps/rejected': -9.585890769958496, 'policy_logps/chosen': -23.385042190551758, 'referece_logps/rejected': -9.530275344848633, 'referece_logps/chosen': -23.44383430480957, 'logits/rejected': -1.8215112686157227, 'logits/chosen': -1.851366639137268, 'epoch': 0.0}
{'loss': 2.2031, 'grad_norm': 0.5053795265563041, 'learning_rate': 2e-05, 'rewards/chosen': -0.09028460085391998, 'rewards/rejected': -0.05079512670636177, 'rewards/accuracies': 0.25, 'rewards/margins': -0.03948947414755821, 'policy_logps/rejected': -42.40083694458008, 'policy_logps/chosen': -50.8589973449707, 'referece_logps/rejected': -41.892887115478516, 'referece_logps/chosen': -49.95615005493164, 'logits/rejected': -1.8599215745925903, 'logits/chosen': -1.8182088136672974, 'epoch': 0.0}
{'loss': 2.1463, 'grad_norm': 1.5392813744766716, 'learning_rate': 2.4e-05, 'rewards/chosen': 0.03585401922464371, 'rewards/rejected': 0.028118658810853958, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0077353585511446, 'policy_logps/rejected': -115.77412414550781, 'policy_logps/chosen': -105.11106872558594, 'referece_logps/rejected': -116.05531311035156, 'referece_logps/chosen': -105.46961975097656, 'logits/rejected': -1.7991235256195068, 'logits/chosen': -1.8062885999679565, 'epoch': 0.0}
{'loss': 2.3095, 'grad_norm': 0.7920730116839058, 'learning_rate': 2.8000000000000003e-05, 'rewards/chosen': 0.00206756591796875, 'rewards/rejected': 0.006773769855499268, 'rewards/accuracies': 0.5, 'rewards/margins': -0.004706203937530518, 'policy_logps/rejected': -9.046695709228516, 'policy_logps/chosen': -9.081700325012207, 'referece_logps/rejected': -9.114433288574219, 'referece_logps/chosen': -9.102375984191895, 'logits/rejected': -1.9635941982269287, 'logits/chosen': -1.9736779928207397, 'epoch': 0.0}
{'loss': 2.1312, 'grad_norm': 0.6010683184906642, 'learning_rate': 3.2000000000000005e-05, 'rewards/chosen': 0.0020067207515239716, 'rewards/rejected': 0.08361747860908508, 'rewards/accuracies': 0.0, 'rewards/margins': -0.08161075413227081, 'policy_logps/rejected': -133.62002563476562, 'policy_logps/chosen': -72.73804473876953, 'referece_logps/rejected': -134.45620727539062, 'referece_logps/chosen': -72.75811767578125, 'logits/rejected': -1.8159174919128418, 'logits/chosen': -1.6403369903564453, 'epoch': 0.0}
{'loss': 2.0961, 'grad_norm': 0.8876103359462113, 'learning_rate': 3.6e-05, 'rewards/chosen': 0.049374744296073914, 'rewards/rejected': 0.022805165499448776, 'rewards/accuracies': 0.75, 'rewards/margins': 0.02656957507133484, 'policy_logps/rejected': -5.190309047698975, 'policy_logps/chosen': -7.96504020690918, 'referece_logps/rejected': -5.418360710144043, 'referece_logps/chosen': -8.45878791809082, 'logits/rejected': -1.8198798894882202, 'logits/chosen': -1.860923171043396, 'epoch': 0.0}
{'loss': 1.8433, 'grad_norm': 1.0202884712135445, 'learning_rate': 4e-05, 'rewards/chosen': -0.16602377593517303, 'rewards/rejected': -0.02333136834204197, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1426924169063568, 'policy_logps/rejected': -55.42015075683594, 'policy_logps/chosen': -76.31970977783203, 'referece_logps/rejected': -55.18683624267578, 'referece_logps/chosen': -74.65947723388672, 'logits/rejected': -1.909131407737732, 'logits/chosen': -1.948362946510315, 'epoch': 0.0}
{'loss': 1.7666, 'grad_norm': 1.2985231887691648, 'learning_rate': 4.4000000000000006e-05, 'rewards/chosen': 0.1616591513156891, 'rewards/rejected': 0.06942398846149445, 'rewards/accuracies': 0.75, 'rewards/margins': 0.09223517030477524, 'policy_logps/rejected': -4.9178290367126465, 'policy_logps/chosen': -19.88329315185547, 'referece_logps/rejected': -5.612069129943848, 'referece_logps/chosen': -21.49988555908203, 'logits/rejected': -1.8372435569763184, 'logits/chosen': -2.0171823501586914, 'epoch': 0.0}
{'loss': 1.4106, 'grad_norm': 3.2423635412015397, 'learning_rate': 4.8e-05, 'rewards/chosen': -0.031533416360616684, 'rewards/rejected': 0.12581633031368256, 'rewards/accuracies': 0.0, 'rewards/margins': -0.15734973549842834, 'policy_logps/rejected': -53.26426315307617, 'policy_logps/chosen': -64.45755004882812, 'referece_logps/rejected': -54.52242660522461, 'referece_logps/chosen': -64.14221954345703, 'logits/rejected': -1.9457205533981323, 'logits/chosen': -1.931994915008545, 'epoch': 0.01}
{'loss': 1.3053, 'grad_norm': 0.901546538953795, 'learning_rate': 5.2000000000000004e-05, 'rewards/chosen': 0.07206019759178162, 'rewards/rejected': 0.047606609761714935, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02445358783006668, 'policy_logps/rejected': -4.481231689453125, 'policy_logps/chosen': -5.042497158050537, 'referece_logps/rejected': -4.957298278808594, 'referece_logps/chosen': -5.763099193572998, 'logits/rejected': -2.0119779109954834, 'logits/chosen': -2.0429294109344482, 'epoch': 0.01}
{'loss': 1.3155, 'grad_norm': 1.2405110208343917, 'learning_rate': 5.6000000000000006e-05, 'rewards/chosen': -0.031695302575826645, 'rewards/rejected': 0.1186513751745224, 'rewards/accuracies': 0.25, 'rewards/margins': -0.15034668147563934, 'policy_logps/rejected': -65.0837173461914, 'policy_logps/chosen': -27.078353881835938, 'referece_logps/rejected': -66.27023315429688, 'referece_logps/chosen': -26.761402130126953, 'logits/rejected': -2.0339412689208984, 'logits/chosen': -1.946448802947998, 'epoch': 0.01}
{'loss': 0.927, 'grad_norm': 1.0914111061506977, 'learning_rate': 6e-05, 'rewards/chosen': -0.042765676975250244, 'rewards/rejected': 0.00455482630059123, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04732050746679306, 'policy_logps/rejected': -5.228912353515625, 'policy_logps/chosen': -9.95995044708252, 'referece_logps/rejected': -5.274460792541504, 'referece_logps/chosen': -9.532293319702148, 'logits/rejected': -1.9157410860061646, 'logits/chosen': -1.9659922122955322, 'epoch': 0.01}
{'loss': 0.8607, 'grad_norm': 1.052156137396122, 'learning_rate': 6.400000000000001e-05, 'rewards/chosen': -0.003576364368200302, 'rewards/rejected': 0.04822399094700813, 'rewards/accuracies': 0.5, 'rewards/margins': -0.051800355315208435, 'policy_logps/rejected': -57.27452850341797, 'policy_logps/chosen': -84.03919982910156, 'referece_logps/rejected': -57.756771087646484, 'referece_logps/chosen': -84.00343322753906, 'logits/rejected': -2.1439132690429688, 'logits/chosen': -2.054022789001465, 'epoch': 0.01}
{'loss': 0.7258, 'grad_norm': 1.0939441508590233, 'learning_rate': 6.800000000000001e-05, 'rewards/chosen': -0.21027402579784393, 'rewards/rejected': -0.24964967370033264, 'rewards/accuracies': 0.5, 'rewards/margins': 0.039375633001327515, 'policy_logps/rejected': -42.018375396728516, 'policy_logps/chosen': -45.261756896972656, 'referece_logps/rejected': -39.52187728881836, 'referece_logps/chosen': -43.15901565551758, 'logits/rejected': -1.708395004272461, 'logits/chosen': -1.596697211265564, 'epoch': 0.01}
{'loss': 0.6177, 'grad_norm': 3.572963540054268, 'learning_rate': 7.2e-05, 'rewards/chosen': -0.43774980306625366, 'rewards/rejected': -0.7152888774871826, 'rewards/accuracies': 1.0, 'rewards/margins': 0.27753907442092896, 'policy_logps/rejected': -57.87127685546875, 'policy_logps/chosen': -55.539894104003906, 'referece_logps/rejected': -50.71839141845703, 'referece_logps/chosen': -51.16239547729492, 'logits/rejected': -1.8502293825149536, 'logits/chosen': -1.7932558059692383, 'epoch': 0.01}
{'loss': 1.0987, 'grad_norm': 2.092531447453429, 'learning_rate': 7.6e-05, 'rewards/chosen': -0.8322144150733948, 'rewards/rejected': -0.26441431045532227, 'rewards/accuracies': 0.25, 'rewards/margins': -0.5678001046180725, 'policy_logps/rejected': -20.347768783569336, 'policy_logps/chosen': -17.889022827148438, 'referece_logps/rejected': -17.703624725341797, 'referece_logps/chosen': -9.566879272460938, 'logits/rejected': -1.8171412944793701, 'logits/chosen': -1.7773857116699219, 'epoch': 0.01}
{'loss': 0.8504, 'grad_norm': 0.7524009659065849, 'learning_rate': 8e-05, 'rewards/chosen': -0.6892353892326355, 'rewards/rejected': -0.5851147770881653, 'rewards/accuracies': 0.5, 'rewards/margins': -0.10412059724330902, 'policy_logps/rejected': -70.13703918457031, 'policy_logps/chosen': -51.395599365234375, 'referece_logps/rejected': -64.285888671875, 'referece_logps/chosen': -44.50324249267578, 'logits/rejected': -1.6716951131820679, 'logits/chosen': -1.5963172912597656, 'epoch': 0.01}
{'loss': 0.7832, 'grad_norm': 4.349373669312355, 'learning_rate': 8.4e-05, 'rewards/chosen': -0.9171971082687378, 'rewards/rejected': -0.8171536922454834, 'rewards/accuracies': 0.25, 'rewards/margins': -0.1000434160232544, 'policy_logps/rejected': -61.10755920410156, 'policy_logps/chosen': -74.97451782226562, 'referece_logps/rejected': -52.93601989746094, 'referece_logps/chosen': -65.80255126953125, 'logits/rejected': -1.6678245067596436, 'logits/chosen': -1.8487502336502075, 'epoch': 0.01}
{'loss': 0.6079, 'grad_norm': 1.8800972635391584, 'learning_rate': 8.800000000000001e-05, 'rewards/chosen': -0.6353602409362793, 'rewards/rejected': -0.8830927014350891, 'rewards/accuracies': 1.0, 'rewards/margins': 0.2477325052022934, 'policy_logps/rejected': -18.91867446899414, 'policy_logps/chosen': -11.609217643737793, 'referece_logps/rejected': -10.087748527526855, 'referece_logps/chosen': -5.255616188049316, 'logits/rejected': -1.3929927349090576, 'logits/chosen': -1.4088020324707031, 'epoch': 0.01}
{'loss': 0.5606, 'grad_norm': 0.9551554455497121, 'learning_rate': 9.200000000000001e-05, 'rewards/chosen': -1.1011217832565308, 'rewards/rejected': -1.432741403579712, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3316196799278259, 'policy_logps/rejected': -55.19106674194336, 'policy_logps/chosen': -62.82931137084961, 'referece_logps/rejected': -40.863651275634766, 'referece_logps/chosen': -51.818092346191406, 'logits/rejected': -1.793150544166565, 'logits/chosen': -1.7925515174865723, 'epoch': 0.01}
{'loss': 0.6651, 'grad_norm': 2.3428486425963326, 'learning_rate': 9.6e-05, 'rewards/chosen': -2.7876369953155518, 'rewards/rejected': -3.3726413249969482, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5850042104721069, 'policy_logps/rejected': -71.11457061767578, 'policy_logps/chosen': -88.06845092773438, 'referece_logps/rejected': -37.388153076171875, 'referece_logps/chosen': -60.192081451416016, 'logits/rejected': -1.6465505361557007, 'logits/chosen': -1.7729480266571045, 'epoch': 0.01}
{'loss': 1.1856, 'grad_norm': 7.740735084265278, 'learning_rate': 0.0001, 'rewards/chosen': -3.6587419509887695, 'rewards/rejected': -3.450742721557617, 'rewards/accuracies': 0.5, 'rewards/margins': -0.20799893140792847, 'policy_logps/rejected': -76.5428466796875, 'policy_logps/chosen': -85.601318359375, 'referece_logps/rejected': -42.03541564941406, 'referece_logps/chosen': -49.01390075683594, 'logits/rejected': -1.6477065086364746, 'logits/chosen': -1.5600147247314453, 'epoch': 0.01}
{'loss': 0.6677, 'grad_norm': 0.24597427707559683, 'learning_rate': 9.999512620046522e-05, 'rewards/chosen': -2.3629400730133057, 'rewards/rejected': -3.052762985229492, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6898230314254761, 'policy_logps/rejected': -36.861610412597656, 'policy_logps/chosen': -29.438692092895508, 'referece_logps/rejected': -6.3339762687683105, 'referece_logps/chosen': -5.809289932250977, 'logits/rejected': -1.3461532592773438, 'logits/chosen': -1.3870506286621094, 'epoch': 0.01}
{'loss': 0.694, 'grad_norm': 0.45952021386138414, 'learning_rate': 9.998050575201771e-05, 'rewards/chosen': -2.066721200942993, 'rewards/rejected': -2.506295680999756, 'rewards/accuracies': 0.5, 'rewards/margins': 0.43957430124282837, 'policy_logps/rejected': -34.95840835571289, 'policy_logps/chosen': -28.86811637878418, 'referece_logps/rejected': -9.895450592041016, 'referece_logps/chosen': -8.20090389251709, 'logits/rejected': -1.6359487771987915, 'logits/chosen': -1.8005762100219727, 'epoch': 0.01}
{'loss': 0.447, 'grad_norm': 5.569171119804986, 'learning_rate': 9.995614150494293e-05, 'rewards/chosen': -3.3413190841674805, 'rewards/rejected': -4.461328983306885, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1200101375579834, 'policy_logps/rejected': -145.78836059570312, 'policy_logps/chosen': -176.65670776367188, 'referece_logps/rejected': -101.17506408691406, 'referece_logps/chosen': -143.2435302734375, 'logits/rejected': -1.5253500938415527, 'logits/chosen': -1.4924721717834473, 'epoch': 0.01}
{'loss': 0.8973, 'grad_norm': 0.7501349725071496, 'learning_rate': 9.992203820909906e-05, 'rewards/chosen': -1.8735089302062988, 'rewards/rejected': -1.6696548461914062, 'rewards/accuracies': 0.5, 'rewards/margins': -0.20385408401489258, 'policy_logps/rejected': -23.270660400390625, 'policy_logps/chosen': -26.77145767211914, 'referece_logps/rejected': -6.57411003112793, 'referece_logps/chosen': -8.036368370056152, 'logits/rejected': -1.7200664281845093, 'logits/chosen': -1.62913179397583, 'epoch': 0.01}
{'loss': 1.0861, 'grad_norm': 10.666950301531903, 'learning_rate': 9.987820251299122e-05, 'rewards/chosen': -2.8813986778259277, 'rewards/rejected': -2.504478931427002, 'rewards/accuracies': 0.5, 'rewards/margins': -0.3769197463989258, 'policy_logps/rejected': -69.1341552734375, 'policy_logps/chosen': -65.26048278808594, 'referece_logps/rejected': -44.08937072753906, 'referece_logps/chosen': -36.446495056152344, 'logits/rejected': -1.5278494358062744, 'logits/chosen': -1.547275424003601, 'epoch': 0.01}
{'loss': 0.5975, 'grad_norm': 0.8159441940868718, 'learning_rate': 9.982464296247522e-05, 'rewards/chosen': -4.449572563171387, 'rewards/rejected': -4.894046306610107, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44447362422943115, 'policy_logps/rejected': -176.4883575439453, 'policy_logps/chosen': -211.5911407470703, 'referece_logps/rejected': -127.54788970947266, 'referece_logps/chosen': -167.0954132080078, 'logits/rejected': -1.65297532081604, 'logits/chosen': -1.577561855316162, 'epoch': 0.01}
{'loss': 0.4759, 'grad_norm': 0.1668470488134813, 'learning_rate': 9.976136999909156e-05, 'rewards/chosen': -2.6452856063842773, 'rewards/rejected': -4.2645182609558105, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6192327737808228, 'policy_logps/rejected': -85.97926330566406, 'policy_logps/chosen': -67.63243865966797, 'referece_logps/rejected': -43.334083557128906, 'referece_logps/chosen': -41.179588317871094, 'logits/rejected': -1.6982569694519043, 'logits/chosen': -1.7103074789047241, 'epoch': 0.01}
{'loss': 0.5023, 'grad_norm': 1.8163528270453606, 'learning_rate': 9.968839595802982e-05, 'rewards/chosen': -2.2153749465942383, 'rewards/rejected': -3.3164784908294678, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1011035442352295, 'policy_logps/rejected': -45.65230941772461, 'policy_logps/chosen': -27.026565551757812, 'referece_logps/rejected': -12.487525939941406, 'referece_logps/chosen': -4.872814178466797, 'logits/rejected': -1.3341050148010254, 'logits/chosen': -1.415932297706604, 'epoch': 0.01}
{'loss': 0.3377, 'grad_norm': 0.5146301961195895, 'learning_rate': 9.96057350657239e-05, 'rewards/chosen': -2.258681297302246, 'rewards/rejected': -3.2426278591156006, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9839465618133545, 'policy_logps/rejected': -40.250492095947266, 'policy_logps/chosen': -26.231922149658203, 'referece_logps/rejected': -7.824213981628418, 'referece_logps/chosen': -3.645108938217163, 'logits/rejected': -1.5913403034210205, 'logits/chosen': -1.5719118118286133, 'epoch': 0.02}
{'loss': 0.4111, 'grad_norm': 2.616606508361238, 'learning_rate': 9.951340343707852e-05, 'rewards/chosen': -5.719611167907715, 'rewards/rejected': -8.964735984802246, 'rewards/accuracies': 0.75, 'rewards/margins': 3.245124340057373, 'policy_logps/rejected': -197.0990753173828, 'policy_logps/chosen': -130.49560546875, 'referece_logps/rejected': -107.45172119140625, 'referece_logps/chosen': -73.29949951171875, 'logits/rejected': -1.4866565465927124, 'logits/chosen': -1.508228063583374, 'epoch': 0.02}
{'loss': 2.3894, 'grad_norm': 2.6593854462432995, 'learning_rate': 9.941141907232765e-05, 'rewards/chosen': -4.554498195648193, 'rewards/rejected': -2.6251721382141113, 'rewards/accuracies': 0.25, 'rewards/margins': -1.9293259382247925, 'policy_logps/rejected': -31.880107879638672, 'policy_logps/chosen': -55.38561248779297, 'referece_logps/rejected': -5.628387451171875, 'referece_logps/chosen': -9.840633392333984, 'logits/rejected': -1.3473273515701294, 'logits/chosen': -1.4168716669082642, 'epoch': 0.02}
{'loss': 1.4256, 'grad_norm': 3.5994244433300984, 'learning_rate': 9.929980185352526e-05, 'rewards/chosen': -6.9365973472595215, 'rewards/rejected': -7.049798488616943, 'rewards/accuracies': 0.25, 'rewards/margins': 0.11320096254348755, 'policy_logps/rejected': -168.248046875, 'policy_logps/chosen': -191.6045684814453, 'referece_logps/rejected': -97.75006866455078, 'referece_logps/chosen': -122.23860931396484, 'logits/rejected': -1.3872594833374023, 'logits/chosen': -1.3966424465179443, 'epoch': 0.02}
{'loss': 1.3579, 'grad_norm': 2.1798964096095066, 'learning_rate': 9.917857354066931e-05, 'rewards/chosen': -2.4493987560272217, 'rewards/rejected': -1.6577246189117432, 'rewards/accuracies': 0.25, 'rewards/margins': -0.7916741371154785, 'policy_logps/rejected': -21.01578140258789, 'policy_logps/chosen': -31.840656280517578, 'referece_logps/rejected': -4.43853759765625, 'referece_logps/chosen': -7.3466691970825195, 'logits/rejected': -1.2391529083251953, 'logits/chosen': -1.2881345748901367, 'epoch': 0.02}
{'loss': 0.8296, 'grad_norm': 5.1525097777576025, 'learning_rate': 9.904775776745958e-05, 'rewards/chosen': -2.460526466369629, 'rewards/rejected': -3.094542980194092, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6340163946151733, 'policy_logps/rejected': -79.31544494628906, 'policy_logps/chosen': -65.9891586303711, 'referece_logps/rejected': -48.37001037597656, 'referece_logps/chosen': -41.38389205932617, 'logits/rejected': -1.4084056615829468, 'logits/chosen': -1.3919428586959839, 'epoch': 0.02}
{'loss': 0.8067, 'grad_norm': 1.6173586547506784, 'learning_rate': 9.890738003669029e-05, 'rewards/chosen': -2.067751884460449, 'rewards/rejected': -2.7882869243621826, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7205349206924438, 'policy_logps/rejected': -73.68804168701172, 'policy_logps/chosen': -55.827518463134766, 'referece_logps/rejected': -45.80517578125, 'referece_logps/chosen': -35.150001525878906, 'logits/rejected': -1.2983378171920776, 'logits/chosen': -1.326220989227295, 'epoch': 0.02}
{'loss': 0.6491, 'grad_norm': 2.312571137854825, 'learning_rate': 9.875746771527816e-05, 'rewards/chosen': -2.28166127204895, 'rewards/rejected': -2.745138168334961, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4634770154953003, 'policy_logps/rejected': -71.56387329101562, 'policy_logps/chosen': -68.18000793457031, 'referece_logps/rejected': -44.11248779296875, 'referece_logps/chosen': -45.36339569091797, 'logits/rejected': -1.4561247825622559, 'logits/chosen': -1.3795008659362793, 'epoch': 0.02}
